{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115c899e-e791-401c-8aa9-e97918ffed1e",
   "metadata": {},
   "source": [
    "# **1. Sementic Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982016ac-1c3d-4ca7-8db0-1aeb6295702c",
   "metadata": {},
   "source": [
    "### 균열 데이터셋을 활용한 Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d0c808-1c59-42db-9720-0f80ab333952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ebbc3f-2b88-40b5-b45b-5cdcc51730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현성을 위한 랜덤시드 고정\n",
    "random_seed = 2024\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.mbenchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ef2d23-cb14-4bf2-8008-a38c01b80190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class CrackDatasets(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, img_transform, mask_transform):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.img_files = []\n",
    "        self.mask_file = []\n",
    "        self.seed = np.random.randint(2024)\n",
    "        for img_name in os.listdir(self.img_dir):\n",
    "            if img_name.split('.')[-1] in ('png', 'jpg'):\n",
    "                self.img_files.append(os.path.join(self.img_dir, img_name))\n",
    "                self.mask_files.append(os.path.join(self.mask_dir, img_name))\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.img_files[i])\n",
    "        if self.img_transform is not None:\n",
    "            random.seed(self.seed)\n",
    "            img = self.img_transform(img)\n",
    "        mask = Image.open(self.mask_files[i]).convert('L') # 그레이스케일로 변환\n",
    "        if self.mask_transform is not None:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a993beb-82a7-407e-9d95-24853219ce6a",
   "metadata": {},
   "source": [
    "# **2. UNET**\n",
    "* 의료 영상 분석에 자주 사용되는 딥러닝 아키텍쳐\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1400/1*qNdglJ1ORP3Gq77MmBLhHQ.png' width=600>\n",
    "\n",
    "* 인코딩(축소)\n",
    "  * 일반적인 컨볼루션 신경망(CNN)\n",
    "  * 컨볼루션과 풀링을 통해 이미지가 점점 작아짐\n",
    "  * 고수준의 특징을 추출\n",
    "* 디코딩(확장)\n",
    "  * 축소 부분에서 얻은 특징을 사용하여 이미지를 원래 크기로 다시 확장\n",
    "  * 업샘플링 연산을 사용하여 이미지의 크기를 증가\n",
    "  * 확장 과정에서 축소 부분에서의 특징을 연결하여 정보를 유지할 수 있도록 함\n",
    "* Skip Connections\n",
    "  * U-Net의 핵심 특징\n",
    "  * 축소 부분의 각 레이어에서의 출력은 확장 부분의 해당 레이어와 연결\n",
    "  * 고수준의 정보와 저수준의 정보가 결합되어 세부적인 부분까지 정확한 이미지 분할이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb0d0bc-b34f-48d1-a4ea-7cf433758608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n",
    "        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n",
    "        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n",
    "        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n",
    "        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.BatchNorm2d(num_features=out_channels),\n",
    "                              nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.BatchNorm2d(num_features=out_channels))\n",
    "        return block\n",
    "\n",
    "    def forward(self, X):\n",
    "        contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256]\n",
    "        contracting_12_out = self.contracting_12(contracting_11_out) # [-1, 64, 128, 128]\n",
    "        contracting_21_out = self.contracting_21(contracting_12_out) # [-1, 128, 128, 128]\n",
    "        contracting_22_out = self.contracting_22(contracting_21_out) # [-1, 128, 64, 64]\n",
    "        contracting_31_out = self.contracting_31(contracting_22_out) # [-1, 256, 64, 64]\n",
    "        contracting_32_out = self.contracting_32(contracting_31_out) # [-1, 256, 32, 32]\n",
    "        contracting_41_out = self.contracting_41(contracting_32_out) # [-1, 512, 32, 32]\n",
    "        contracting_42_out = self.contracting_42(contracting_41_out) # [-1, 512, 16, 16]\n",
    "        middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n",
    "        expansive_11_out = self.expansive_11(middle_out) # [-1, 512, 32, 32]\n",
    "        expansive_12_out = self.expansive_12(torch.cat((expansive_11_out, contracting_41_out), dim=1)) # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n",
    "        expansive_21_out = self.expansive_21(expansive_12_out) # [-1, 256, 64, 64]\n",
    "        expansive_22_out = self.expansive_22(torch.cat((expansive_21_out, contracting_31_out), dim=1)) # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n",
    "        expansive_31_out = self.expansive_31(expansive_22_out) # [-1, 128, 128, 128]\n",
    "        expansive_32_out = self.expansive_32(torch.cat((expansive_31_out, contracting_21_out), dim=1)) # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n",
    "        expansive_41_out = self.expansive_41(expansive_32_out) # [-1, 64, 256, 256]\n",
    "        expansive_42_out = self.expansive_42(torch.cat((expansive_41_out, contracting_11_out), dim=1)) # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n",
    "        output_out = self.output(expansive_42_out) # [-1, num_classes, 256, 256]\n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e1feb-3937-4685-979f-5a27e511bbc8",
   "metadata": {},
   "source": [
    "# **3. Dice Score와 IoU 메트릭 함수 정의하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533a4fef-24fe-4edd-9472-7457d05286a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice coefficient: 두 개의 집합 간의 유사성을 측정하는 데 사용되는 통계적인 지표\n",
    "# 2×∣A∩B∣ / ∣A∣+∣B∣ \n",
    "# 0에서 1까지의 값을 가지며, 1에 가까울수록 두 집합이 유사\n",
    "# 1e-6: 0.000001\n",
    "def dice_coeff(input, target, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # assert 조건, \"에러 메세지\"\n",
    "    assert input.size() == target.size()\n",
    "    assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "    inter = 2*(input * target).sum(dim=sum_dim)\n",
    "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "    # torch.where(): 조건에 따른 연산함수\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "    \n",
    "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "    return dice.mean() \n",
    "    \n",
    "\n",
    "# IoU(Intersection over Union): 객체 검출 및 객체 분할과 같은 컴퓨터 비전 작업에서 사용되는 평가 지표\n",
    "# 두 개의 영역 또는 객체가 주어졌을 때, IoU는 교집합을 합집합으로 나눈 것을 나타냄. 0에서 1사이의 값을 갖음\n",
    "def iou(y_true, y_pred, epsilon: float = 1e-6):\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    return (intersection + epsilon) / (union + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a03f2-e6e9-45c4-b389-ef2655d9ebdf",
   "metadata": {},
   "source": [
    "# **4. 학습, 검증 함수 정의하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814a7859-ea66-41dd-ae5c-7d4fa43c8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def find_latest_model_path(dir):\n",
    "    model_paths = []\n",
    "    epochs = []\n",
    "    for path in Path(dir).glob('*.pth'):\n",
    "        if 'epoch' not in path.stem:\n",
    "            continue\n",
    "        model_paths.append(path)\n",
    "        parts = path.stem.split('_')\n",
    "        epoch = int(parts[-1])\n",
    "        epochs.append(epoch)\n",
    "\n",
    "    if len(epochs) > 0:\n",
    "        epochs = np.array(epochs)\n",
    "        max_idx = np.argmax(epochs)\n",
    "        return model_paths[max_idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# param_groups: 옵티마이저 객체 속성. 요소는 딕셔너리이며 매개변수 그룹에 대한 정보를 저장\n",
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704149f0-0971-440d-b40c-a0a792fd8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, valid_loader, model_dir, n_epoch, batch_size, lr, device):\n",
    "    latest_model_path = find_latest_model_path(model_dir)\n",
    "    best_model_path = os.path.join(*[model_dir, 'model_best.pth'])\n",
    "\n",
    "    if latest_model_path is not None:\n",
    "        state = torch.load(latest_model_path)\n",
    "        epoch = state['epoch']\n",
    "        model.load_state_dict(state['model'])\n",
    "        assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist!'\n",
    "        best_state = torch.load(latest_model_path)\n",
    "        min_val_los = best_state['valid_loss']\n",
    "\n",
    "        print(f'Restored model: {epoch}, Min validation loss: {min_val_los}')\n",
    "        epoch += 1\n",
    "        print(f'{epoch}')\n",
    "    else:\n",
    "        print('epoch: 0')\n",
    "        epoch = 0\n",
    "        min_val_los = 9999\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(epoch, n_epoch):\n",
    "        adjust_learning_rate(optimizer, epoch, lr)\n",
    "        tq = tqdm.tqdm(total=(len(train_loader) * batch_size))\n",
    "        tq.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        losses = AverageMeter()\n",
    "        t_iou = 0\n",
    "        t_dice = 0\n",
    "\n",
    "        model.train()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            # Variable: 텐서를 대체하기 위해 사용되던 클래스(과거 버전의 텐서)\n",
    "            input_var = Variable(input).to(device)\n",
    "            target_var = Variable(target).to(device)\n",
    "\n",
    "            masks_pred = model(input_var)\n",
    "            pred = F.sigmoid(masks_pred)\n",
    "            target_mask = target_var\n",
    "            \n",
    "            pred[pred>0.5] = 1\n",
    "            pred[pred<=0.5] = 0\n",
    "            target_mask[target_mask>0.5] = 1\n",
    "            target_mask[target_mask<=0.5] = 0\n",
    "\n",
    "            t_dice += dice_coeff(pred, target_mask)\n",
    "            t_iou += iou(pred, target_mask)\n",
    "\n",
    "            masks_probs_flat = masks_pred.view(-1)\n",
    "            true_masks_flat = target_var.view(-1)\n",
    "\n",
    "            loss = criterion(masks_probs_flat, true_masks_flat)\n",
    "            losses.update(loss)\n",
    "            tq.set_postfix(loss='{:.5f}'.format(losses.avg))\n",
    "            tq.update(batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'train miou : {t_iou/len(train_loader):.5f} train dice score : {t_dice/len(train_loader):.5f}')\n",
    "        valid_metrics = valid(model, valid_loader, criterion)\n",
    "        valid_loss = valid_metrics['valid_loss']\n",
    "        valid_dice = valid_metrics['v_dice']\n",
    "        valid_iou = valid_metrics['v_iou']\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'valid_loss = {valid_loss:.5f}')\n",
    "        print(f'valid miou : {valid_iou/len(valid_loader):.5f} valid dice score : {valid_dice/len(valid_loader):.5f}')\n",
    "        tq.close()\n",
    "\n",
    "        epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pth'])\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': losses.avg\n",
    "        }, epoch_model_path)\n",
    "\n",
    "        if valid_loss < min_val_los:\n",
    "            min_val_los = valid_loss\n",
    "\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'valid_loss': valid_loss,\n",
    "                'train_loss': losses.avg\n",
    "            }, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b1f6cc-6db3-497a-a5d8-4d4fc50eb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, val_loader, criterion):\n",
    "    losses = AverageMeter()\n",
    "    v_iou = 0\n",
    "    v_dice = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input_var = Variable(input).to(device)\n",
    "            target_var = Variable(target).to(device)\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "            losses.update(loss.item(), input_var.size(0))\n",
    "            pred = F.sigmoid(output)\n",
    "            target_mask = target_var\n",
    "\n",
    "            pred[pred>0.5] = 1\n",
    "            pred[pred<=0.5] = 0\n",
    "            target_mask[target_mask>0.5] = 1\n",
    "            target_mask[target_mask<=0.5] = 0\n",
    "\n",
    "            v_dice += dice_coeff(pred, target_mask)\n",
    "            v_iou += iou(pred, target_mask)\n",
    "            \n",
    "    return {'valid_loss': losses.avg, 'v_dice': v_dice, 'v_iou': v_iou}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f8857-021d-4ce3-8d87-123eb3864e49",
   "metadata": {},
   "source": [
    "# **5. 파라미터 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d62651-2d71-4138-99e6-66834ff10139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더\n",
    "model_dir = './model_weights'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 저장 폴더\n",
    "data_dir = './crack_segmentation_dataset/train'\n",
    "DIR_IMG = os.path.join(data_dir, 'images')\n",
    "DIR_MASK = os.path.join(data_dir, 'masks')\n",
    "\n",
    "# Device 할당\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def51d8b-614d-4adc-9179-8fad7af79872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
